{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T11:09:42.355627Z",
     "start_time": "2017-10-13T11:09:42.004538Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-27T14:18:59.318806Z",
     "start_time": "2017-09-27T14:18:59.192810Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "<p> Keras <img src=\"../images/keras-logo-small.jpg\", width=\"48\", align=\"left\", text=\"Keras\"> </p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Keras is a model-level library, providing high-level building blocks for developing deep learning models. It does not handle itself low-level operations such as tensor products, convolutions and so on. Instead, it relies on a specialized, well-optimized tensor manipulation library to do so, serving as the \"backend engine\" of Keras. Rather than picking one single tensor library and making the implementation of Keras tied to that library, Keras handles the problem in a modular way, and several different backend engines can be plugged seamlessly into Keras.\n",
    "\n",
    "At this time, Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend.\n",
    "\n",
    "TensorFlow is an open-source symbolic tensor manipulation framework developed by Google.\n",
    "Theano is an open-source symbolic tensor manipulation framework developed by LISA Lab at Université de Montréal.\n",
    "CNTK is an open-source toolkit for deep learning developed by Microsoft.\n",
    "\n",
    "\n",
    "\n",
    "## Models\n",
    "\n",
    "There are two types of models available in Keras: the Sequential model and the Model class used with functional API.\n",
    "\n",
    "Sequential() only stacks layers upon previous ones sequentially like a stack or queue, it's good for setup a pipeline-like architecture.\n",
    "\n",
    "Using a Sequantial class you wan to stack layers on top of each other. You can see the list of possible layers using the command:\n",
    "\n",
    "With the functional API, it is easy to re-use trained models: you can treat any model as if it were a layer, by calling it on a tensor. Note that by calling a model you aren't just re-using the architecture of the model, you are also re-using its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T11:09:54.949894Z",
     "start_time": "2017-10-13T11:09:42.427413Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Activation',\n",
       " 'ActivityRegularization',\n",
       " 'Add',\n",
       " 'AlphaDropout',\n",
       " 'AtrousConv1D',\n",
       " 'AtrousConv2D',\n",
       " 'AtrousConvolution1D',\n",
       " 'AtrousConvolution2D',\n",
       " 'Average',\n",
       " 'AveragePooling1D',\n",
       " 'AveragePooling2D',\n",
       " 'AveragePooling3D',\n",
       " 'AvgPool1D',\n",
       " 'AvgPool2D',\n",
       " 'AvgPool3D',\n",
       " 'BatchNormalization',\n",
       " 'Bidirectional',\n",
       " 'Concatenate',\n",
       " 'Conv1D',\n",
       " 'Conv2D',\n",
       " 'Conv2DTranspose',\n",
       " 'Conv3D',\n",
       " 'Conv3DTranspose',\n",
       " 'ConvLSTM2D',\n",
       " 'ConvRecurrent2D',\n",
       " 'Convolution1D',\n",
       " 'Convolution2D',\n",
       " 'Convolution2DTranspose',\n",
       " 'Convolution3D',\n",
       " 'Cropping1D',\n",
       " 'Cropping2D',\n",
       " 'Cropping3D',\n",
       " 'Deconv2D',\n",
       " 'Deconv3D',\n",
       " 'Deconvolution2D',\n",
       " 'Deconvolution3D',\n",
       " 'Dense',\n",
       " 'Dot',\n",
       " 'Dropout',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'Flatten',\n",
       " 'GRU',\n",
       " 'GaussianDropout',\n",
       " 'GaussianNoise',\n",
       " 'GlobalAveragePooling1D',\n",
       " 'GlobalAveragePooling2D',\n",
       " 'GlobalAveragePooling3D',\n",
       " 'GlobalAvgPool1D',\n",
       " 'GlobalAvgPool2D',\n",
       " 'GlobalAvgPool3D',\n",
       " 'GlobalMaxPool1D',\n",
       " 'GlobalMaxPool2D',\n",
       " 'GlobalMaxPool3D',\n",
       " 'GlobalMaxPooling1D',\n",
       " 'GlobalMaxPooling2D',\n",
       " 'GlobalMaxPooling3D',\n",
       " 'Highway',\n",
       " 'Input',\n",
       " 'InputLayer',\n",
       " 'InputSpec',\n",
       " 'K',\n",
       " 'LSTM',\n",
       " 'Lambda',\n",
       " 'Layer',\n",
       " 'LeakyReLU',\n",
       " 'LocallyConnected1D',\n",
       " 'LocallyConnected2D',\n",
       " 'Masking',\n",
       " 'MaxPool1D',\n",
       " 'MaxPool2D',\n",
       " 'MaxPool3D',\n",
       " 'MaxPooling1D',\n",
       " 'MaxPooling2D',\n",
       " 'MaxPooling3D',\n",
       " 'Maximum',\n",
       " 'MaxoutDense',\n",
       " 'Merge',\n",
       " 'Multiply',\n",
       " 'PReLU',\n",
       " 'Permute',\n",
       " 'Recurrent',\n",
       " 'RepeatVector',\n",
       " 'Reshape',\n",
       " 'SeparableConv2D',\n",
       " 'SeparableConvolution2D',\n",
       " 'SimpleRNN',\n",
       " 'SpatialDropout1D',\n",
       " 'SpatialDropout2D',\n",
       " 'SpatialDropout3D',\n",
       " 'Subtract',\n",
       " 'ThresholdedReLU',\n",
       " 'TimeDistributed',\n",
       " 'UpSampling1D',\n",
       " 'UpSampling2D',\n",
       " 'UpSampling3D',\n",
       " 'Wrapper',\n",
       " 'ZeroPadding1D',\n",
       " 'ZeroPadding2D',\n",
       " 'ZeroPadding3D',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'activations',\n",
       " 'add',\n",
       " 'advanced_activations',\n",
       " 'average',\n",
       " 'concatenate',\n",
       " 'constraints',\n",
       " 'conv_utils',\n",
       " 'convolutional',\n",
       " 'convolutional_recurrent',\n",
       " 'copy',\n",
       " 'core',\n",
       " 'deserialize',\n",
       " 'deserialize_keras_object',\n",
       " 'division',\n",
       " 'dot',\n",
       " 'embeddings',\n",
       " 'func_dump',\n",
       " 'func_load',\n",
       " 'has_arg',\n",
       " 'initializers',\n",
       " 'interfaces',\n",
       " 'local',\n",
       " 'maximum',\n",
       " 'merge',\n",
       " 'multiply',\n",
       " 'noise',\n",
       " 'normalization',\n",
       " 'np',\n",
       " 'pooling',\n",
       " 'python_types',\n",
       " 'recurrent',\n",
       " 'regularizers',\n",
       " 'serialize',\n",
       " 'subtract',\n",
       " 'warnings',\n",
       " 'wrappers']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "dir(keras.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T11:09:54.954988Z",
     "start_time": "2017-10-13T11:09:54.951760Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add layers in two ways:\n",
    "* with the add method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T11:09:54.979508Z",
     "start_time": "2017-10-13T11:09:54.956311Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-27T16:15:46.324364Z",
     "start_time": "2017-09-27T16:15:46.321229Z"
    }
   },
   "source": [
    "* with object initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T11:09:55.008767Z",
     "start_time": "2017-10-13T11:09:54.981544Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(32, input_shape=(784,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T11:09:55.021736Z",
     "start_time": "2017-10-13T11:09:55.010179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module keras.layers.core:\n",
      "\n",
      "class Dense(keras.engine.topology.Layer)\n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: if the input to the layer has a rank greater than 2, then\n",
      " |  it is flattened prior to the initial dot product with `kernel`.\n",
      " |  \n",
      " |  # Example\n",
      " |  \n",
      " |  ```python\n",
      " |      # as first layer in a sequential model:\n",
      " |      model = Sequential()\n",
      " |      model.add(Dense(32, input_shape=(16,)))\n",
      " |      # now the model will take as input arrays of shape (*, 16)\n",
      " |      # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |      # after the first layer, you don't need to specify\n",
      " |      # the size of the input anymore:\n",
      " |      model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  # Arguments\n",
      " |      units: Positive integer, dimensionality of the output space.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you don't specify anything, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      nD tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |      The most common situation would be\n",
      " |      a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      nD tensor with shape: `(batch_size, ..., units)`.\n",
      " |      For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |      the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Container), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peceptron\n",
    "\n",
    "## Task: create a perceptron that reproduce a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "def linear_f(x):\n",
    "    \"\"\"Simple linear function\"\"\"\n",
    "    return 2*x+1\n",
    "\n",
    "_x = np.linspace(1,2, num = 1e3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T10:08:39.079176Z",
     "start_time": "2017-10-13T10:08:39.044931Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: [[ 7.02902555]] - actual: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make prediction with the current model\n",
    "print(\"Predicted value: {pred} - actual: {actual}\".format(pred=m.predict(np.array((3,))),\n",
    "                                                          actual=linear_f(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T10:08:47.734173Z",
     "start_time": "2017-10-13T10:08:47.556776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x123b5ecc0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1235ce710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check how the model fits the input\n",
    "\n",
    "plt.plot(_x, linear_f(_x))\n",
    "predictions = m.predict(_x) \n",
    "plt.plot(_x, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
